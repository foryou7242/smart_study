{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Session in module tensorflow.python.client.session object:\n",
      "\n",
      "class Session(BaseSession)\n",
      " |  A class for running TensorFlow operations.\n",
      " |  \n",
      " |  A `Session` object encapsulates the environment in which `Operation`\n",
      " |  objects are executed, and `Tensor` objects are evaluated. For\n",
      " |  example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Build a graph.\n",
      " |  a = tf.constant(5.0)\n",
      " |  b = tf.constant(6.0)\n",
      " |  c = a * b\n",
      " |  \n",
      " |  # Launch the graph in a session.\n",
      " |  sess = tf.Session()\n",
      " |  \n",
      " |  # Evaluate the tensor `c`.\n",
      " |  print(sess.run(c))\n",
      " |  ```\n",
      " |  \n",
      " |  A session may own resources, such as\n",
      " |  @{tf.Variable}, @{tf.QueueBase},\n",
      " |  and @{tf.ReaderBase}. It is important to release\n",
      " |  these resources when they are no longer required. To do this, either\n",
      " |  invoke the @{tf.Session.close} method on the session, or use\n",
      " |  the session as a context manager. The following two examples are\n",
      " |  equivalent:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Using the `close()` method.\n",
      " |  sess = tf.Session()\n",
      " |  sess.run(...)\n",
      " |  sess.close()\n",
      " |  \n",
      " |  # Using the context manager.\n",
      " |  with tf.Session() as sess:\n",
      " |    sess.run(...)\n",
      " |  ```\n",
      " |  \n",
      " |  The\n",
      " |  [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      " |  protocol buffer exposes various configuration options for a\n",
      " |  session. For example, to create a session that uses soft constraints\n",
      " |  for device placement, and log the resulting placement decisions,\n",
      " |  create a session as follows:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Launch the graph in a session that allows soft device placement and\n",
      " |  # logs the placement decisions.\n",
      " |  sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
      " |                                          log_device_placement=True))\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Session\n",
      " |      BaseSession\n",
      " |      SessionInterface\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exec_type, exec_value, exec_tb)\n",
      " |  \n",
      " |  __init__(self, target='', graph=None, config=None)\n",
      " |      Creates a new TensorFlow session.\n",
      " |      \n",
      " |      If no `graph` argument is specified when constructing the session,\n",
      " |      the default graph will be launched in the session. If you are\n",
      " |      using more than one graph (created with `tf.Graph()` in the same\n",
      " |      process, you will have to use different sessions for each graph,\n",
      " |      but each graph can be used in multiple sessions. In this case, it\n",
      " |      is often clearer to pass the graph to be launched explicitly to\n",
      " |      the session constructor.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: (Optional.) The execution engine to connect to.\n",
      " |          Defaults to using an in-process engine. See\n",
      " |          @{$distributed$Distributed TensorFlow}\n",
      " |          for more examples.\n",
      " |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      " |        config: (Optional.) A\n",
      " |          [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      " |          protocol buffer with configuration options for the session.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  reset(target, containers=None, config=None)\n",
      " |      Resets resource containers on `target`, and close all connected sessions.\n",
      " |      \n",
      " |      A resource container is distributed across all workers in the\n",
      " |      same cluster as `target`.  When a resource container on `target`\n",
      " |      is reset, resources associated with that container will be cleared.\n",
      " |      In particular, all Variables in the container will become undefined:\n",
      " |      they lose their values and shapes.\n",
      " |      \n",
      " |      NOTE:\n",
      " |      (i) reset() is currently only implemented for distributed sessions.\n",
      " |      (ii) Any sessions on the master named by `target` will be closed.\n",
      " |      \n",
      " |      If no resource containers are provided, all containers are reset.\n",
      " |      \n",
      " |      Args:\n",
      " |        target: The execution engine to connect to.\n",
      " |        containers: A list of resource container name strings, or `None` if all of\n",
      " |          all the containers are to be reset.\n",
      " |        config: (Optional.) Protocol buffer with configuration options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      " |          resetting containers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSession:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  as_default(self)\n",
      " |      Returns a context manager that makes this object the default session.\n",
      " |      \n",
      " |      Use with the `with` keyword to specify that calls to\n",
      " |      @{tf.Operation.run} or @{tf.Tensor.eval} should be executed in\n",
      " |      this session.\n",
      " |      \n",
      " |      ```python\n",
      " |      c = tf.constant(..)\n",
      " |      sess = tf.Session()\n",
      " |      \n",
      " |      with sess.as_default():\n",
      " |        assert tf.get_default_session() is sess\n",
      " |        print(c.eval())\n",
      " |      ```\n",
      " |      \n",
      " |      To get the current default session, use @{tf.get_default_session}.\n",
      " |      \n",
      " |      *N.B.* The `as_default` context manager *does not* close the\n",
      " |      session when you exit the context, and you must close the session\n",
      " |      explicitly.\n",
      " |      \n",
      " |      ```python\n",
      " |      c = tf.constant(...)\n",
      " |      sess = tf.Session()\n",
      " |      with sess.as_default():\n",
      " |        print(c.eval())\n",
      " |      # ...\n",
      " |      with sess.as_default():\n",
      " |        print(c.eval())\n",
      " |      \n",
      " |      sess.close()\n",
      " |      ```\n",
      " |      \n",
      " |      Alternatively, you can use `with tf.Session():` to create a\n",
      " |      session that is automatically closed on exiting the context,\n",
      " |      including when an uncaught exception is raised.\n",
      " |      \n",
      " |      *N.B.* The default session is a property of the current thread. If you\n",
      " |      create a new thread, and wish to use the default session in that\n",
      " |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      " |      thread's function.\n",
      " |      \n",
      " |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      " |      the current default graph. If you are using multiple graphs, and\n",
      " |      `sess.graph` is different from the value of @{tf.get_default_graph},\n",
      " |      you must explicitly enter a `with sess.graph.as_default():` block\n",
      " |      to make `sess.graph` the default graph.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A context manager using this session as the default session.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Closes this session.\n",
      " |      \n",
      " |      Calling this method frees all resources associated with the session.\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      " |          closing the TensorFlow session.\n",
      " |  \n",
      " |  list_devices(self)\n",
      " |      Lists available devices in this session.\n",
      " |      \n",
      " |      ```python\n",
      " |      devices = sess.list_devices()\n",
      " |      for d in devices:\n",
      " |        print(d.name)\n",
      " |      ```\n",
      " |      \n",
      " |      Each element in the list has the following properties:\n",
      " |       - `name`: A string with the full name of the device. ex:\n",
      " |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      " |       - `device_type`: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      " |       - `memory_limit`: The maximum amount of memory available on the device.\n",
      " |            Note: depending on the device, it is possible the usable memory could\n",
      " |            be substantially less.\n",
      " |      Raises:\n",
      " |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      " |        invalid state, or network errors occur).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of devices in the session.\n",
      " |  \n",
      " |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      " |      Returns a Python callable that runs a particular step.\n",
      " |      \n",
      " |      The returned callable will take `len(feed_list)` arguments whose types\n",
      " |      must be compatible feed values for the respective elements of `feed_list`.\n",
      " |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      " |      argument to the returned callable must be a numpy ndarray (or something\n",
      " |      convertible to an ndarray) with matching element type and shape. See\n",
      " |      @{tf.Session.run} for details of the allowable feed key and value types.\n",
      " |      \n",
      " |      The returned callable will have the same return type as\n",
      " |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      " |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      " |      it will return `None`.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A value or list of values to fetch. See @{tf.Session.run}\n",
      " |          for details of the allowable fetch types.\n",
      " |        feed_list: (Optional.) A list of `feed_dict` keys. See\n",
      " |          @{tf.Session.run} for details of the allowable feed key types.\n",
      " |        accept_options: (Optional.) Iff `True`, the returned `Callable` will be\n",
      " |          able to accept @{tf.RunOptions} and @{tf.RunMetadata} as optional\n",
      " |          keyword arguments `options` and `run_metadata`, respectively, with\n",
      " |          the same syntax and semantics as @{tf.Session.run}, which is useful\n",
      " |          for certain use cases (profiling and debugging) but will result in\n",
      " |          measurable slowdown of the `Callable`'s performance. Default: `False`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A function that when called will execute the step defined by\n",
      " |        `feed_list` and `fetches` in this session.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      " |          as arguments to @{tf.Session.run}.\n",
      " |  \n",
      " |  partial_run(self, handle, fetches, feed_dict=None)\n",
      " |      Continues the execution with more feeds and fetches.\n",
      " |      \n",
      " |      This is EXPERIMENTAL and subject to change.\n",
      " |      \n",
      " |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      " |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      " |      list of feeds and fetches that will be used in the subsequent\n",
      " |      `partial_run` calls.\n",
      " |      \n",
      " |      The optional `feed_dict` argument allows the caller to override\n",
      " |      the value of tensors in the graph. See run() for more information.\n",
      " |      \n",
      " |      Below is a simple example:\n",
      " |      \n",
      " |      ```python\n",
      " |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      " |      r1 = math_ops.add(a, b)\n",
      " |      r2 = math_ops.multiply(r1, c)\n",
      " |      \n",
      " |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      " |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      " |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        handle: A handle for a sequence of partial runs.\n",
      " |        fetches: A single graph element, a list of graph elements,\n",
      " |          or a dictionary whose values are graph elements or lists of graph\n",
      " |          elements (see documentation for `run`).\n",
      " |        feed_dict: A dictionary that maps graph elements to values\n",
      " |          (described above).\n",
      " |      \n",
      " |      Returns:\n",
      " |        Either a single value if `fetches` is a single graph element, or\n",
      " |        a list of values if `fetches` is a list, or a dictionary with the\n",
      " |        same keys as `fetches` if that is a dictionary\n",
      " |        (see documentation for `run`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        tf.errors.OpError: Or one of its subclasses on error.\n",
      " |  \n",
      " |  partial_run_setup(self, fetches, feeds=None)\n",
      " |      Sets up a graph with feeds and fetches for partial run.\n",
      " |      \n",
      " |      This is EXPERIMENTAL and subject to change.\n",
      " |      \n",
      " |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      " |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A single graph element, or a list of graph elements.\n",
      " |        feeds: A single graph element, or a list of graph elements.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A handle for partial run.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      " |          closed).\n",
      " |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      " |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      " |  \n",
      " |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      " |      Runs operations and evaluates tensors in `fetches`.\n",
      " |      \n",
      " |      This method runs one \"step\" of TensorFlow computation, by\n",
      " |      running the necessary graph fragment to execute every `Operation`\n",
      " |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      " |      `feed_dict` for the corresponding input values.\n",
      " |      \n",
      " |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      " |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      " |      elements at its leaves.  A graph element can be one of the following types:\n",
      " |      \n",
      " |      * An @{tf.Operation}.\n",
      " |        The corresponding fetched value will be `None`.\n",
      " |      * A @{tf.Tensor}.\n",
      " |        The corresponding fetched value will be a numpy ndarray containing the\n",
      " |        value of that tensor.\n",
      " |      * A @{tf.SparseTensor}.\n",
      " |        The corresponding fetched value will be a\n",
      " |        @{tf.SparseTensorValue}\n",
      " |        containing the value of that sparse tensor.\n",
      " |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      " |        numpy ndarray containing the handle of that tensor.\n",
      " |      * A `string` which is the name of a tensor or operation in the graph.\n",
      " |      \n",
      " |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      " |      where the leaves are replaced by the corresponding values returned by\n",
      " |      TensorFlow.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |         a = tf.constant([10, 20])\n",
      " |         b = tf.constant([1.0, 2.0])\n",
      " |         # 'fetches' can be a singleton\n",
      " |         v = session.run(a)\n",
      " |         # v is the numpy array [10, 20]\n",
      " |         # 'fetches' can be a list.\n",
      " |         v = session.run([a, b])\n",
      " |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      " |         # 1-D array [1.0, 2.0]\n",
      " |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      " |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      " |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      " |         # v is a dict with\n",
      " |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      " |         # 'b' (the numpy array [1.0, 2.0])\n",
      " |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      " |         # [10, 20].\n",
      " |      ```\n",
      " |      \n",
      " |      The optional `feed_dict` argument allows the caller to override\n",
      " |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      " |      one of the following types:\n",
      " |      \n",
      " |      * If the key is a @{tf.Tensor}, the\n",
      " |        value may be a Python scalar, string, list, or numpy ndarray\n",
      " |        that can be converted to the same `dtype` as that\n",
      " |        tensor. Additionally, if the key is a\n",
      " |        @{tf.placeholder}, the shape of\n",
      " |        the value will be checked for compatibility with the placeholder.\n",
      " |      * If the key is a\n",
      " |        @{tf.SparseTensor},\n",
      " |        the value should be a\n",
      " |        @{tf.SparseTensorValue}.\n",
      " |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      " |        should be a nested tuple with the same structure that maps to their\n",
      " |        corresponding values as above.\n",
      " |      \n",
      " |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      " |      of the corresponding key.\n",
      " |      \n",
      " |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      " |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      " |      on).\n",
      " |      \n",
      " |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      " |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      " |      example, when users turn on tracing in `options`, the profiled info will be\n",
      " |      collected into this argument and passed back.\n",
      " |      \n",
      " |      Args:\n",
      " |        fetches: A single graph element, a list of graph elements,\n",
      " |          or a dictionary whose values are graph elements or lists of graph\n",
      " |          elements (described above).\n",
      " |        feed_dict: A dictionary that maps graph elements to values\n",
      " |          (described above).\n",
      " |        options: A [`RunOptions`] protocol buffer\n",
      " |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      " |      \n",
      " |      Returns:\n",
      " |        Either a single value if `fetches` is a single graph element, or\n",
      " |        a list of values if `fetches` is a list, or a dictionary with the\n",
      " |        same keys as `fetches` if that is a dictionary (described above).\n",
      " |        Order in which `fetches` operations are evaluated inside the call\n",
      " |        is undefined.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      " |          closed).\n",
      " |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      " |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      " |          `Tensor` that doesn't exist.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSession:\n",
      " |  \n",
      " |  graph\n",
      " |      The graph that was launched in this session.\n",
      " |  \n",
      " |  graph_def\n",
      " |      A serializable version of the underlying TensorFlow graph.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      " |        the underlying TensorFlow graph.\n",
      " |  \n",
      " |  sess_str\n",
      " |      The TensorFlow process to which this session will connect.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from SessionInterface:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello tensorflow'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hello = tf.constant(\"hello tensorflow\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building graph\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.5)\n",
    "node3 = tf.add(node1, node2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1 = Tensor(\"Const_4:0\", shape=(), dtype=float32), node2 = Tensor(\"Const_5:0\", shape=(), dtype=float32) , node3 = Tensor(\"Add_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(f'node1 = {node1}, node2 = {node2} , node3 = {node3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.0, 4.5)\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "#run graph\n",
    "print(sess.run((node1, node2)))\n",
    "print(sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function placeholder in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "placeholder(dtype, shape=None, name=None)\n",
      "    Inserts a placeholder for a tensor that will be always fed.\n",
      "    \n",
      "    **Important**: This tensor will produce an error if evaluated. Its value must\n",
      "    be fed using the `feed_dict` optional argument to `Session.run()`,\n",
      "    `Tensor.eval()`, or `Operation.run()`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    x = tf.placeholder(tf.float32, shape=(1024, 1024))\n",
      "    y = tf.matmul(x, x)\n",
      "    \n",
      "    with tf.Session() as sess:\n",
      "      print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "    \n",
      "      rand_array = np.random.rand(1024, 1024)\n",
      "      print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
      "    ```\n",
      "    \n",
      "    @compatibility(eager)\n",
      "    Placeholders are not compatible with eager execution.\n",
      "    @end_compatibility\n",
      "    \n",
      "    Args:\n",
      "      dtype: The type of elements in the tensor to be fed.\n",
      "      shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "        specified, you can feed a tensor of any shape.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` that may be used as a handle for feeding a value, but not\n",
      "      evaluated directly.\n",
      "    \n",
      "    Raises:\n",
      "      RuntimeError: if eager execution is enabled\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  5.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "add_node = a + b\n",
    "print(sess.run(add_node, feed_dict={a:3, b:4.5}))\n",
    "print(sess.run(add_node, feed_dict={a:[1,2], b:[2,3]}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ranks d dimension\n",
    "#shape rank 2 = [d1, d2] rank 3 = [d1,d2,d3] rank1 = [d1]...\n",
    "#dataType = float32, 64 int32 64\n",
    "t = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
